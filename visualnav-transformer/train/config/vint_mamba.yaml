# ViNT-Mamba Configuration


project_name: vint-mamba
run_name: vint-mamba

# training setup
use_wandb: False  # 启用wandb监控训练
train: True
batch_size: 256  # 降低以支持更大context_size
eval_batch_size: 16   # 评估时减小batch_size避免OOM
epochs: 100
gpu_ids: [0]
num_workers: 4
lr: 5e-4
optimizer: adamw
clipping: False
max_norm: 1.
scheduler: "cosine"
warmup: True 
warmup_epochs: 4
cyclic_period: 10
plateau_patience: 3
plateau_factor: 0.5
seed: 0

# model params
model_type: mamba_vint  # Use Mamba-based model
obs_encoder: "efficientnet-b0"
obs_encoding_size: 512
late_fusion: False

# Mamba-specific parameters (参考MTIL优化)
mamba_d_state: 64         # State space dimension (MTIL为512，导航任务降低)
mamba_d_conv: 4           # Convolution kernel size
mamba_expand: 2           # Expansion factor  
mamba_headdim: 64         # Head dimension (MTIL为128，导航任务降低)
mamba_num_blocks: 4       # Number of Mamba blocks
mamba_chunk_size: 256     # Chunk size - Mamba内部分chunk处理，关键优化！
mamba_use_mem_eff: True   # False 禁用mem_eff避免额外显存开销

# normalization for the action space
normalize: True

# context - Mamba可以处理更长的上下文！
context_type: temporal
context_size: 20  # 先从10开始，稳定后可逐步增大

# tradeoff between action and distance prediction loss
alpha: 0.5

# distance bounds for distance and action and distance predictions 
distance:
  min_dist_cat: 0
  max_dist_cat: 20
action:
  min_dist_cat: 0
  max_dist_cat: 10
close_far_threshold: 10

# action output params
len_traj_pred: 5
learn_angle: True

# dataset specific parameters
image_size: [80, 60] # width, height
goal_type: "image"

datasets:
  go_stanford:
    data_folder: /home/czl/Navigation/datasets/go_stanford
    train: vint_train/data/data_splits/go_stanford/train/
    test: vint_train/data/data_splits/go_stanford/test/
    end_slack: 0
    goals_per_obs: 2
    negative_mining: True

# logging stuff
print_log_freq: 100
image_log_freq: 1000
num_images_log: 8
pairwise_test_freq: 0
eval_fraction: 0.25
wandb_log_freq: 10
eval_freq: 1

